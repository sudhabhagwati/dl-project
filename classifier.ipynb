{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from inspect import signature\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('seaborn-poster')\n",
    "style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for random number generator\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the excel sheet into a dataframe\n",
    "dataset = pd.read_excel('training_data/pubchem.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features as input dimension\n",
    "input_dim = dataset.shape[1]-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input matrix to neural network of size (no. of training data X no. of features)\n",
    "X = np.asarray(dataset[dataset.columns[1:(dataset.shape[1]-1)]])\n",
    "\n",
    "# true output labels\n",
    "Y = np.asarray(dataset['IC50'])\n",
    "Y = (Y < 100000)\n",
    "Y = Y.astype(int)\n",
    "\n",
    "# shuffle and reshape the data \n",
    "Z = np.zeros((X.shape[0],X.shape[1]+1))\n",
    "Z[:,:-1] = X\n",
    "Z[:,-1] = Y\n",
    "Z = shuffle(Z)\n",
    "X = Z[:,:-1]\n",
    "Y = Z[:,-1]\n",
    "Y = Y.reshape(dataset.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# normalize and scale both training and test inputs\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "sc.fit(X_test)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sequential neural network model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(882, input_dim=input_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model using test data \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# compare the model predictions with true output labels using confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print( 'True negatives: ' + str(cm[0][0]))\n",
    "print( 'False postives: ' + str(cm[0][1]))\n",
    "print( 'False negatives: ' + str(cm[1][0]))\n",
    "print( 'True positives: ' + str(cm[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training data\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# evaluate the model on test data\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "y_pred= model.predict(X_test).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, 'b-' ,label='(area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) curve')\n",
    "plt.legend(loc='best')\n",
    "# plt.savefig('fig-c1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prc curve\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot([0, 1], [0.5, 0.5], 'k--')\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.plot(recall, precision, 'b-', label='(Average precision-recall score: = {:.3f})'.format(average_precision))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve (PRC)')\n",
    "# plt.savefig('fig-c2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the unknown data set from csv file to dataframe\n",
    "udataset = pd.read_csv('library_to_screen/pubchem_maybridge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curate the unknown dataset to remove duplicates\n",
    "cudataset = udataset\n",
    "d =[]\n",
    "for i in range(udataset.shape[0]-1):\n",
    "    if udataset.loc[i]['Name']==udataset.loc[i+1]['Name']:\n",
    "        d.append(i+1)\n",
    "cudataset = udataset.drop(udataset.index[d])\n",
    "print(cudataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the unknown dataset to numpy array to give it as input to neural network model\n",
    "uX = np.asarray(cudataset[cudataset.columns[1:(cudataset.shape[1])]])\n",
    "\n",
    "# normalize and scale the unknown input matrix to be screened\n",
    "sc.fit(uX)\n",
    "uX = sc.transform(uX)\n",
    "\n",
    "# screen the unknown data using neural network model\n",
    "uY = model.predict(uX)\n",
    "\n",
    "# convert the model outputs to true/false (or) active/inactive (or) 1/0\n",
    "uYc = (uY > 0.5)\n",
    "\n",
    "# count the number of actives/true's/1's \n",
    "hits = np.sum(uYc)\n",
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN output found and removed\n",
    "np.argwhere(np.isnan(uY)>0)[0]\n",
    "uY[24124] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the names of the actives screened using the neural network model in a list\n",
    "idx = np.nonzero(uY > 0.5)[0]\n",
    "d =[]\n",
    "for i in list(idx):\n",
    "    d.append(udataset.iloc[i]['Name'])\n",
    "\n",
    "# save the list of names into a csv file\n",
    "with open(\"output_hits.csv\", \"w\") as outfile:\n",
    "    for entries in d:\n",
    "        outfile.write(entries)\n",
    "        outfile.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
